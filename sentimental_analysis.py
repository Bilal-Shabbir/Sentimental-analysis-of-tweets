# -*- coding: utf-8 -*-
"""final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-_8Dsjgur_pBYg0kR-k34FR3fK1ZwdUx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import csv
import re
import string
from sklearn.metrics import f1_score
from scipy.sparse import csr_matrix
from sklearn.metrics import precision_score, recall_score, confusion_matrix
from nltk.stem import PorterStemmer
from scipy.sparse import hstack
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC, SVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')
file_path='/content/drive/MyDrive/development.csv'
df=pd.read_csv(file_path, encoding='utf-8')

df

from google.colab import drive
#drive.mount('/content/drive')
file_path='/content/drive/MyDrive/evaluation.csv'
df_e=pd.read_csv(file_path, encoding='utf-8')
df_e

def f_day(pds):
  tmp=pds.split(' ')
  return tmp[0]

def f_month(pds):
  tmp=pds.split(' ')
  return tmp[1]

def f_date(pds):
  tmp=pds.split(' ')
  return int(tmp[2])

def f_time(pds):
  tmp=pds.split(' ')
  return int(tmp[3].split(':')[0])

def f_year(pds):
  tmp=pds.split(' ')
  return int(tmp[5])

df['day'] = df['date'].apply(f_day)
df['month'] = df['date'].apply(f_month)
df['date_i'] = df['date'].apply(f_date)
df['time'] = df['date'].apply(f_time)
df

df_e['day'] = df_e['date'].apply(f_day)
df_e['month'] = df_e['date'].apply(f_month)
df_e['date_i'] = df_e['date'].apply(f_date)
df_e['time'] = df_e['date'].apply(f_time)
df_e

ps = PorterStemmer()
def cleanTxt(text):
  #text = re.sub(r'@[A-Za-z0-9]+','', text)
  #text = re.sub('[^a-zA-Z]'," ",text)
  #text = re.sub(r'#','',text)
  #text = re.sub(r'RT[\s]','',text)
  #text = re.sub(r'http?:\/\/\S+','',text)
  text = text.lower()
  text = text.split()
  text = [ps.stem(word) for word in text]
  text = " ".join(text)
  for punct in string.punctuation:
            text = text.replace(punct, '')
  
  return text

df['text'] = df['text'].apply(cleanTxt)
df

df_e['text'] = df_e['text'].apply(cleanTxt)
df_e

df_y=df['sentiment']
df_cat=df[['user','day','month']]  #  'user', ,'month'
df_text=df['text']
df_num=df[['date_i', 'time']]  # ,'time'

dfe_cat=df_e[['user','day','month']]  #  'user',  'user', ,'month'
dfe_text=df_e['text']
dfe_num=df_e[['date_i', 'time']]  # ,'time'

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder(handle_unknown='ignore')
oneHot=enc.fit_transform(df_cat)
oneHot_e=enc.fit_transform(dfe_cat)

df_user = df['user']
dfe_user = df_e['user']

svc_f1_f1 = []
nb_f1_fea = []
nb_f1_f1 = []

for m_f in range(2000, 4700, 200):
  uv =  TfidfVectorizer(max_features=m_f, min_df=2)
  user_tfidf = uv.fit_transform(df_user)
  #usere_tfid = uv.transform(dfe_user)

  vectorizer = TfidfVectorizer(max_features=m_f, min_df=1)
  text = vectorizer.fit_transform(df_text)
  #text_e = vectorizer.transform(dfe_text)
  
  data=hstack((df_num,oneHot,text))  # , user_tfidf
  #data_e=hstack((dfe_num,oneHot_e,text_e, usere_tfid))
  """print(data.shape)
  print(data_e.shape)"""

  x_train, x_valid, y_train, y_test = train_test_split(data, df_y, test_size=0.30, shuffle=True, stratify=df_y)
  
  c=0
  clf = MultinomialNB()
  clf.fit(x_train, y_train)
  nb_f1_fea.append(m_f)
  nb_f1_f1.append(f1_score(y_test, clf.predict(x_valid)))

  clf = LinearSVC(dual=False)
  clf.fit(x_train, y_train)
  svc_f1_f1.append(f1_score(y_test, clf.predict(x_valid)))

  """clf.fit(x_train, y_train)
  predicted = clf.predict(x_valid)
  precision = precision_score(y_test, predicted)
  recall = recall_score(y_test, predicted)
  f1 = f1_score(y_test, predicted)
  confusion = confusion_matrix(y_test, predicted)
  print("precision for C=%s: %s" %(m_f,precision))
  print("recall for C=%s: %s" %(m_f,recall))
  print("f1 for C=%s: %s" %(m_f,f1))"""
  #print(confusion)

f1_df = pd.DataFrame()
f1_df['features'] = nb_f1_fea
f1_df['multinomial'] = nb_f1_f1
f1_df['svc'] = svc_f1_f1
f1_df



uv =  TfidfVectorizer(max_features=2500, min_df=2)
#user_tfidf = uv.fit_transform(df_user)
#usere_tfid = uv.transform(dfe_user)

vectorizer = TfidfVectorizer(max_features=2500, min_df=2)
text = vectorizer.fit_transform(df_text)
text_e = vectorizer.transform(dfe_text)
  
data=hstack((df_num,oneHot,text))  # , user_tfidf
data_e=hstack((dfe_num,oneHot_e,text_e))  #, usere_tfid
x_train, x_valid, y_train, y_test = train_test_split(data, df_y, test_size=0.30, shuffle=True, stratify=df_y)



from sklearn.model_selection import ParameterGrid

params = {
    
    "dual" : [False],
    "tol": [1e-5, 1e-7, 1e-9],  # 1e-5, , 1e-9
    "C": [.01, .03, .07, .11]  # .01, .03, , .09, .11
}

accuracies = []
grid_svc = ParameterGrid(params)
for config in grid_svc:
    clf = LinearSVC(**config)
    clf.fit(x_train, y_train)
    accuracies.append(f1_score(y_test, clf.predict(x_valid)))
max(accuracies)

best_config_svc = list(grid_svc)[np.argmax(accuracies)]
best_config_svc

from sklearn.model_selection import ParameterGrid

params = {
     'fit_prior':[False, True],
     'alpha': [0.6, 0.8, 1]
}

accuracies1 = []
con = []
grid_nb = ParameterGrid(params)
for config in grid_nb:
    con.append(config)
    clf = MultinomialNB(**config)
    clf.fit(x_train, y_train)
    accuracies1.append(f1_score(y_test, clf.predict(x_valid)))
max(accuracies1)

best_config_mn = list(grid_nb)[np.argmax(accuracies1)]
best_config_mn



#data_e=hstack((dfe_num,oneHot_e,text_e))
clf = LinearSVC(**best_config_svc)
clf.fit(x_train, y_train)
res = clf.predict(data_e)

dfrn = pd.DataFrame (data = {"Predicted":res})
dfrn.to_csv('y_predictSVC.csv',index_label = "Id")
!cp y_predictSVC.csv "drive/My Drive/"

clf = MultinomialNB(**best_config_mn)
clf.fit(data, df['sentiment'])
res = clf.predict(data_e)

dfrn = pd.DataFrame (data = {"Predicted":res})
dfrn.to_csv('y_predictMN.csv',index_label = "Id")
!cp y_predictMN.csv "drive/My Drive/"



